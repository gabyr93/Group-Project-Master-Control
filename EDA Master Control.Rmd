---
title: "EDA Master Control"
author: "Josh, Joel, Corinn, Gaby"
date: "2026-02-17"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    toc-title: "Contents"
    embed-resources: true
execute:
  include: true
  eval: true
  warning: false
  message: false
---

# Introduction

### Business Problem

MasterControl is a SaaS provider offering two core software suites: *QX (Quality Solutions)* and *MX (Manufacturing Solutions)*. While QX has over 20 years of market maturity, MX is a newer offering launched approximately four years ago. MX currently underperforms QX with a 12.7% lead progression rate, compared to 19.7% for QX. Leadership believes the current targeting strategy results in sales pursuing leads that are less likely to convert, creating missed opportunities and inefficient resource allocation.

### Analytic Problem

Our analytic task is to identify the **industries**, **company characteristics**, and **job titles** associated with higher MX progression rates. The target variable is **Lead Outcome**, where a lead is considered successful if it reached **SQL**, **SQO**, or **Won**.

The goal of EDA is to:\
- Understand the structure and quality of the data\
- Examine relationships between lead attributes and Lead Outcome\
- Identify which features appear predictive and should be prioritized in modeling\
- Detect missingness, inconsistency, and outlier behavior

### Scope

The output of this project will be recommendations for: - Which industries to target\
- Which job titles represent high-value decision makers\
- How Marketing and Sales can prioritize outreach for the MX product\
- Improvements to prospect data-capture on the MasterControl website

Predicting churn or customer retention is **out of scope**.

### Success Metrics

-   **Primary metric:** Lead progression rate (SQL/SQO/Won)\
-   **Goal:** Increase MX progression from **12.7% → 16–18%**, moving toward the QX benchmark of 19.7%

Success means enabling MasterControl Sales to focus on high-potential profiles that historically progress at above-average rates.

### Project Management

Team members include **Corinn, Josh, Joel, and Gaby**, meeting weekly with the following milestones:\
- Feb 1 — Business problem statement finalized\
- Feb 22 — EDA complete\
- Mar 22 — Modeling & evaluation\
- Apr 8 — Final presentation

------------------------------------------------------------------------

### Questions to Guide EDA

1.  **Data Quality**
    -   What variables exist? How many leads?\
    -   Are job titles and industry columns clean or messy?\
    -   Which variables have missing values?\
    -   Is the missing data random, or does it follow a pattern?
    -   Are there any duplicate leads?
2.  **Target Variable**
    -   What is the overall MX success rate?\
    -   Is the target imbalanced?
3.  **Job Titles**
    -   Which job title patterns (e.g., Director, Manager, Engineer) appear most in converted leads?\
    -   Which technical/manufacturing roles convert best?
4.  **Industry**
    -   Which industries show the highest conversion rates?\
    -   Are specific NAICS groups highly predictive?\
    -   Can differences between conversion rates of the products be explained by industry differences?
5.  **Account Characteristics**
    -   Do company size, revenue, or region relate to successful MX outcomes?
6.  **Interactions**
    -   Do specific title + industry combinations show high conversion?
7.  **Modeling Implications**
    -   Which variables look most promising?\
    -   Which variables need transformations or cleaning?

# Data Exploration

### Setup

```{r Setup, warning=FALSE}

# install.packages
pacman::p_load(tidyverse,stringr,tidytext,quanteda,quanteda.textplots,janitor,skimr,recipes)
```

### Load Data

```{r Load Data, warning=FALSE}

# Load Data
leads <- read_csv("QAL Performance for MSBA.csv")


# Basic structure
dim(leads)
glimpse(leads)

# Clean column names for easier coding
leads <- clean_names(leads)
names(leads)

# Quick preview
head(leads)

# Basic summary statistics
summary(leads)

# Check missing values 
colSums(is.na(leads))

#view data set
#view(leads)

# Check for duplicate rows by qal_id
sum(duplicated(leads$qal_id))

# Check which leads are duplicated
leads$qal_id[duplicated(leads$qal_id)]

```

### Dataset Overview

The leads dataset contains 16,815 rows and 14 columns. Each row represents a Qualified Account Lead (QAL) for MasterControl. After cleaning column names, the primary fields fall into the following categories:

**Account / site context:**

-   **acct_primary_site_function:** describes the primary activity at the customer site (e.g., Food and beverage, Small-molecule API, Sterile injectables).\
-   **acct_manufacturing_model:** indicates how manufacturing is managed (e.g., Consumer Packaged Goods, In-House, Hospital/Investor model).\
-   **acct_target_industry:** the industry segment of the account (e.g., Pharma & BioTech, Medical Device, Non-Life Science).

**Contact-level information:**

-   **contact_lead_title:** the job title of the lead or contact (e.g., QA Manager, VP Quality & Regulatory Affairs).\
-   **contact_lead_id:** identifier for the individual contact; may repeat if a person is tied to multiple QAL records.

**QAL identifiers and lead outcomes:**

-   **qal_id:** unique identifier for the QAL record.\
-   **next_stage_c:** the lead outcome or progression stage (e.g., SQL, SQO, Won, Recycled). This is our target variable identifier. This will be converted into a binary success indicator for modeling.

**Account segmentation and territory:**

-   **acct_territory_rollup:** geographic region (Americas, EMEA, APAC & Oceania).\
-   **acct_tier_rollup:** account size/tier (Small, Medium, Large), useful for segmentation.

**Product and marketing channel:**

-   **solution:** specific MasterControl product family engaged (Mx, Qx, Ax, Logbooks).\
-   **solution_rollup:** product family grouping used to distinguish MX from QX.\
-   **last_tactic_campaign_channel:** most recent marketing touchpoint (e.g., Email, Online Ads, Outbound Prospecting).

**Time**

-   **qal_cohort_date:** date when the QAL entered the pipeline, ranging from early 2024 to early 2026.

All variables except the cohort date are categorical and will be treated as factors during modeling. The dataset includes a mix of account attributes, contact information, product engagement, and progression outcomes—providing multiple angles to explore what drives higher MX success. There are 0 duplicated leads in the dataset, meaning every qal_id is unique, therefore no leads were imputed twice and will only be counted once in analysis. The next step is to evaluate missingness and data quality across these fields to understand how each variable will behave in downstream analysis.

### Missing Data

```{r }

# Count missing values per column
missing_values <- leads %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "n_missing") %>%
  mutate(
    pct_missing = 100 * n_missing / nrow(leads)
  ) %>%
  arrange(desc(pct_missing))

missing_values

```

#### Missing Data Overview

The dataset contains several fields with notable missingness. The table below shows the number and percentage of missing values for each variable. Three variables have substantial missingness:

-   **acct_primary_site_function — 40.9% missing**\
-   **acct_manufacturing_model — 40.9% missing**\
-   **contact_lead_title — 38.1% missing**

These three variables represent important account and contact attributes. Their high level of missingness suggests that many QAL records lack basic information about what the site does, how it manufactures, or who the contact person is. Because job titles are central to this project, the missingness in contact_lead_title will be especially important in modeling and may require grouping into an "Unknown" category.

Moderate missingness appears in:

-   **next_stage_c — 2.87% missing**\
    These records have no known lead outcome and will be excluded when computing success rates.

-   **acct_territory_rollup — 0.79% missing**

Low missingness (less than 0.3%) appears in:

-   **acct_target_industry (45 missing)**
-   **acct_tier_rollup (45 missing)**
-   **contact_lead_id (3 missing)**

These complete variables can be used reliably for segmentation and cohort-based analysis.

Overall, the missing data pattern indicates that contact and site-level details are inconsistently collected, while product, territory, and outcome fields are much more complete. For modeling, we will likely need to consolidate missing categories rather than impute them, since these fields represent high-cardinality categorical attributes.

#### Verify Missing Values

According to the data dictionary, the percentage of missing information across variables is minimal, with the exception of job titles. Specifically, the documentation reports:

-   **contact/lead title:** 29.21% missing\
-   \*\*next_stage\_\_c:\*\* 2.37% missing\
-   **acct_territory_rollup:** 0.79% missing\
-   **acct_manufacturing_model:** 0.61% missing\
-   **acct_primary_site_function:** 0.36% missing\
-   **All other variables:** less than 0.3% missing

Based on this documentation, account-level variables such as industry, manufacturing model, and site function are expected to be highly complete and reliable for segmentation analysis.

To validate these assumptions, we will verify whether the dataset used in this analysis reflects the same missingness levels reported in the data dictionary.

```{r create-na-summary,  echo=FALSE, include=FALSE}
na_summary <- leads %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
  mutate(pct_missing = round(100 * n_missing / nrow(leads), 2)) %>%
  arrange(desc(pct_missing))

na_summary
```

```{r verify-missing-data}

# Check blank strings (optional)
sum(leads$acct_primary_site_function == "", na.rm = TRUE)
sum(leads$acct_manufacturing_model == "", na.rm = TRUE)

dict_missing <- tibble::tribble(
  ~variable, ~dict_pct_missing,
  "contact_lead_title", 29.21,
  "next_stage_c", 2.37,
  "acct_territory_rollup", 0.79,
  "acct_manufacturing_model", 0.61,
  "acct_primary_site_function", 0.36,
  "acct_tier_rollup", 0.27,
  "acct_target_industry", 0.27,
  "contact_lead_id", 0.02
)

compare_missing <- na_summary %>%
  left_join(dict_missing, by = "variable") %>%
  mutate(diff_pct = round(pct_missing - dict_pct_missing, 2)) %>%
  arrange(desc(pct_missing))

compare_missing


```

##### Results

The results show that there are no blank string values in either acct_primary_site_function or acct_manufacturing_model. This confirms that missing information in these variables is recorded as NA rather than empty strings.

As shown in the table comparison, the observed levels of missingness differ substantially from those reported in the data dictionary.

#### Veracity of the data

Some variables include placeholder categories such as “Not Enough Info Found” and “Unknown,” which reflect incomplete classification rather than true missing data. These will be treated as explicit categories in the analysis to evaluate whether incomplete enrichment affects lead progression.

```{r not-enough-unknown}

#unique_labels <- lapply(leads %>% select(where(is.character)), function(x) sort(unique(x)))
#unique_labels

counts_not_enough_unknown <- leads %>%
  select(where(is.character)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  filter(str_detect(str_to_lower(value), "not.*enough|enough.*info|unknown")) %>%
  count(variable, value, sort = TRUE) %>%
  group_by(variable) %>%
  mutate(pct = round(100 * n / nrow(leads), 2)) %>%
  ungroup()

counts_not_enough_unknown


```

In addition to true NA values, some variables contain placeholder categories like “Not Enough Info Found” and “Unknown.” These don’t represent simple data entry gaps, but rather cases where the system could not properly classify the account. Combined with the high percentage of NA values, this suggests that account-level information is not fully complete in this dataset. Since missingness itself may be meaningful, these categories will be treated explicitly in the analysis rather than removed.

### Analyzing Missing Data

##### Missingness vs. Lead Progression (Success Rate by Product)

In this section, we test whether **missing enrichment fields** are associated with lower lead progression (i.e., whether missingness is **random** or acts as a **signal** of lead quality).

First, we restrict the dataset to leads with a **known outcome** (`next_stage_c`) so we can compute success rates reliably. We then create a binary target variable, `success`, where leads that reached **SQL, SQO, or Won** are labeled `1` and all other outcomes are labeled `0`.

Next, we create indicator flags that capture whether key enrichment fields are missing: site function (`site_missing`), manufacturing model (`mfg_missing`), and job title (`title_missing`), plus a combined flag (`site_or_mfg_missing`) that identifies leads missing either site or manufacturing information.

Finally, we summarize the **count of leads** and the **success rate** for missing vs not-missing groups, broken out by `solution_rollup` (Mx, Qx, Ax), and visualize the results to compare progression rates across products and missingness conditions.

```{r Analyzing Missing Data}


# Keep only rows with a known outcome, and create binary success target
leads_clean <- leads %>%
  filter(!is.na(next_stage_c)) %>%
  mutate(success = if_else(next_stage_c %in% c("SQL","SQO","Won"), 1, 0))

# Create missingness flags for the key enrichment fields (plus combined flag)
leads_clean_flags <- leads_clean %>%
  mutate(
    site_missing        = is.na(acct_primary_site_function),
    mfg_missing         = is.na(acct_manufacturing_model),
    title_missing       = is.na(contact_lead_title),
    site_or_mfg_missing = site_missing | mfg_missing
  )

# Reshape to long format and compute counts + success rates
missingness_results <- leads_clean_flags %>%
  pivot_longer(
    cols = c(site_missing, mfg_missing, site_or_mfg_missing, title_missing),
    names_to = "missing_type",
    values_to = "missing_flag"
  ) %>%
  group_by(solution_rollup, missing_type, missing_flag) %>%
  summarise(
    n = n(),
    success_rate = round(mean(success) * 100, 2),
    .groups = "drop"
  ) %>%
  arrange(solution_rollup, missing_type, desc(missing_flag))

plot_df <- missingness_results %>%
  filter(missing_type %in% c("site_or_mfg_missing", "title_missing")) %>%
  mutate(
    missing_flag = if_else(missing_flag, "Missing", "Not missing"),
    missing_type = recode(
      missing_type,
      "site_or_mfg_missing" = "Site OR Manufacturing Missing",
      "title_missing" = "Job Title Missing"
    )
  )

plot_df

ggplot(plot_df, aes(x = solution_rollup, y = success_rate, fill = missing_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = paste0("n=", n)),
            position = position_dodge(width = 0.9),
            vjust = -0.3, size = 3) +
  facet_wrap(~ missing_type) +
  labs(
    title = "Lead Progression Rate by Missing Enrichment",
    x = "Solution Rollup",
    y = "Success Rate (%)",
    fill = ""
  ) +
  theme_minimal()

```

##### Interpretation of Output

Missing enrichment is **strongly linked to lower progression**, especially for **site function + manufacturing model**.

-   **MX:** `site_or_mfg_missing` = TRUE → **0.88%** (n=1,360) vs FALSE → **18.84%** (n=2,765).\
    `title_missing` = TRUE → **8.89%** (n=1,158) vs FALSE → **14.49%** (n=2,967).

-   **QX:** `site_or_mfg_missing` = TRUE → **1.23%** (n=5,291) vs FALSE → **34.95%** (n=6,889).\
    `title_missing` = TRUE → **12.90%** (n=5,025) vs FALSE → **25.51%** (n=7,155).

-   **AX:** large differences but **very small n (13–14)** → interpret cautiously.

**Conclusion:** missingness is **not random** and should be kept as a **signal** (use missingness flags or explicit “Missing/Unknown” categories in modeling).

#### **Find a pattern with missing data**

##### MX Only: Where True Missingness Clusters

###### Composition of NA-Missing Leads by Channel, Tier, Territory, and Industry

In this section, we focus specifically on **MX leads** to understand whether missing enrichment fields follow a consistent pattern. We first restrict the data to records with a **known outcome** (`next_stage_c`) so success rates are comparable, then create a binary `success` indicator (SQL/SQO/Won = 1, otherwise = 0). Next, we define two missingness flags: `site_or_mfg_missing` (missing either site function or manufacturing model) and `title_missing` (missing job title).

Using these flags, we compare the composition of the missing vs not-missing groups across key categorical dimensions—**marketing channel**, **account tier**, **territory**, and **target industry**—by calculating within-group percentages. This helps identify where missingness is concentrated (e.g., specific channels or industries), and provides evidence that missing values may reflect systematic differences in lead source or profile rather than random data entry gaps.

```{r NA Sample Pattern}
mx_miss <- leads %>%
  filter(!is.na(next_stage_c)) %>%
  mutate(success = if_else(next_stage_c %in% c("SQL","SQO","Won"), 1, 0)) %>%
  filter(solution_rollup == "Mx") %>%
  mutate(
    site_or_mfg_missing = is.na(acct_primary_site_function) | is.na(acct_manufacturing_model),
    title_missing = is.na(contact_lead_title)
  )

# Pattern: NA group mix by channel (top 10)
mx_miss %>%
  group_by(site_or_mfg_missing, last_tactic_campaign_channel) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_missing) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_missing, desc(pct)) %>%
  slice_head(n = 10)

# Pattern: NA group mix by tier
mx_miss %>%
  group_by(site_or_mfg_missing, acct_tier_rollup) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_missing) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_missing, desc(pct))

# Visualization
mx_miss %>%
  group_by(site_or_mfg_missing, last_tactic_campaign_channel) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_missing) %>%
  mutate(pct = n / sum(n)) %>%
  ggplot(aes(x = reorder(last_tactic_campaign_channel, pct), y = pct, fill = site_or_mfg_missing)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    title = "MX: Channel composition for leads with vs without Site/Manufacturing missing",
    x = "Last Tactic Campaign Channel",
    y = "Share within group",
    fill = "Site/Mfg Missing"
  ) +
  theme_minimal()

#  Pattern: NA group mix by territory (MX)
mx_miss %>%
  group_by(site_or_mfg_missing, acct_territory_rollup) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_missing) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_missing, desc(pct))

# Pattern: NA group mix by target industry (MX) - top 10
mx_miss %>%
  group_by(site_or_mfg_missing, acct_target_industry) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_missing) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_missing, desc(pct)) %>%
  slice_head(n = 10)




```

##### Interpretation of the Output (MX)

Missing site/manufacturing enrichment in **MX** is **not random**. When this info is missing, leads are more likely to be **Small tier** (32.94% vs 16.60%) and more likely to come from **digital/inbound channels** (Online Ads, SEO, Direct/Inbound, Directory Listing), while being less associated with **Email/External Demand Gen**.

Missingness also varies by **region and industry**: the missing group is **less concentrated in the Americas** (49.04% vs 55.08%) and more in **EMEA** (28.53% vs 22.24%). The strongest pattern is **industry**—missing leads are much more likely to be **Non-Life Science** (50.96% vs 13.35%) and less likely to be **Pharma & BioTech** or **Medical Device**.

**Conclusion:** These missing values are not happening by accident. For MX leads, “missing site/manufacturing info” shows up more often in certain types of leads:

-   smaller accounts

-   leads coming from digital/inbound channels (online ads, SEO, direct/inbound, directory)

-   leads from EMEA more than the Americas

-   leads in Non-Life Science more than Pharma & BioTech or Medical Device

This matters because it means “missing” is telling us something about the lead itself and how it entered the system. In practice, missing enrichment can be treated like a warning sign that the lead may be lower quality or less well-qualified, or that the channel/source collects less complete information.

#### **MX Only: Where Low-Enrichment (“Low Info”) Clusters**

##### Composition of Low-Info Leads Using NA + Placeholder Values

In this section, we expand the definition of “missing” enrichment beyond true `NA` values. For two key fields—`acct_primary_site_function` and `acct_manufacturing_model`.We create a **Low Info** indicator that captures both:

-   **True missing values (`NA`)**, and

-   **Placeholder values** that represent incomplete enrichment (e.g., "Unknown", "Not Enough Info Found", "MISSING/BLANK", or empty strings).

Then we focus only on MX leads with a known outcome, and we compare the composition of the Low Info group vs the not Low Info group across:

-   marketing channel (last_tactic_campaign_channel)

-   account tier (acct_tier_rollup)

-   territory (acct_territory_rollup)

-   target industry (acct_target_industry)

```{r Pattern Check Including Low Info Bucket (MX)}

mx_lowinfo <- leads %>%
  filter(!is.na(next_stage_c)) %>%
  mutate(success = if_else(next_stage_c %in% c("SQL","SQO","Won"), 1, 0)) %>%
  filter(solution_rollup == "Mx") %>%
  mutate(
    # define "low info" as NA OR placeholders
    site_lowinfo =
      is.na(acct_primary_site_function) |
      str_to_lower(str_trim(acct_primary_site_function)) %in% c("unknown", "not enough info found", "missing/blank", ""),
    mfg_lowinfo =
      is.na(acct_manufacturing_model) |
      str_to_lower(str_trim(acct_manufacturing_model)) %in% c("unknown", "not enough info found", "missing/blank", ""),
    site_or_mfg_lowinfo = site_lowinfo | mfg_lowinfo
  )

# 1) Channel mix
mx_lowinfo %>%
  group_by(site_or_mfg_lowinfo, last_tactic_campaign_channel) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_lowinfo) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_lowinfo, desc(pct)) %>%
  slice_head(n = 10)

# 2) Tier mix
mx_lowinfo %>%
  group_by(site_or_mfg_lowinfo, acct_tier_rollup) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_lowinfo) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_lowinfo, desc(pct))

# 3) Territory mix
mx_lowinfo %>%
  group_by(site_or_mfg_lowinfo, acct_territory_rollup) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_lowinfo) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_lowinfo, desc(pct))

# 4) Target industry mix (top 10)
mx_lowinfo %>%
  group_by(site_or_mfg_lowinfo, acct_target_industry) %>%
  summarise(n = n(), .groups="drop") %>%
  group_by(site_or_mfg_lowinfo) %>%
  mutate(pct = round(100 * n / sum(n), 2)) %>%
  arrange(site_or_mfg_lowinfo, desc(pct)) %>%
  slice_head(n = 10)
```

#### Conclusion

For MX, “Low Info” enrichment is a meaningful signal. It is more common for:

-   smaller accounts

-   digital/inbound channels (Online Ads, SEO, Directory Listing)

-   EMEA compared to the Americas

-   Non-Life Science accounts (much higher share than in the complete-enrichment group)

Because these differences are large (especially by industry), we should not treat missing/placeholder values as random noise. Instead, we can keep a Low Info flag as a feature and/or combine missing/placeholder categories into a consistent Low Info level for modeling.

### Contact Lead Title - Additional Cleaning Steps

Before we do any in depth cleaning and standardization, we start by checking to see the number of unique and missing values for contact_lead_title field. 

This field is free form entry, therefore this field has a huge variation in job titles. In future modeling, this will create additional noise and difficulty in interpretation. 

```{r}

leads |>
  summarise(n = n(), n_unique = n_distinct(contact_lead_title),
            n_missing = sum(is.na(contact_lead_title) | contact_lead_title == ""))
```
**Unique Contact Lead Titles**

There are 5,791 unique contact lead titles within the dataset. The goal is to reduce the number of unique values to make grouping/clustering simpler for further analysis.

#### Pre-Processing Cleaning

Pre-processing steps are completed to reduce the number of unique values. This includes removing punctuation or special characters, numbers, errant spacing, converting to lower case and removing stop words.

```{r}
#remove special characters
leads <- leads |> mutate(
  contact_lead_title = contact_lead_title |>
    str_to_lower() |>
    str_replace_all("[^a-z\\s]", "") |>
    str_replace_all("\\s+", " ") |>
    str_trim()
)

stop_words_vec <- tidytext::stop_words$word

leads <- leads |>
  mutate(
    contact_lead_title = map_chr(
      contact_lead_title,
      ~ if (is.na(.x)) {
          NA_character_ #preserves NA values for now instead of turning to a string with value of NA
        } else {
          words <- str_split(.x, " ")[[1]]
          paste(words[!words %in% stop_words_vec], collapse = " ")
        }
    )
  )

```

After this cleaning, we see the number of unique is still quite high, with an improvement of about 8% (445 values).

```{r}

leads |>
  summarise(n = n(), n_unique = n_distinct(contact_lead_title),
            n_missing = sum(is.na(contact_lead_title) | contact_lead_title == ""))
```

**Pre-Processing Cleaning Output**
The number of unique values decreased from 5,791 to 5,346. There needs futher cleaning and or title grouping to lower this value.

#### Common Contact Title Groupings

To try and further reduce the number of unique values, AI was leveraged to come up with a map of common abbreviations and typing errors. This value map was then applied to the data, replacing the values where they occurred. 

```{r}
title_map <- c(
  # --- common misspellings / normalization ---
  "cheif" = "chief",
  "chif" = "chief",
  "cheif executive officer" = "chief executive officer",
  "chief exec officer" = "chief executive officer",
  "chief exec" = "chief executive officer",
  "chief executive" = "chief executive officer",
  "chief operating" = "chief operating officer",
  "chief financial" = "chief financial officer",
  "chief technology" = "chief technology officer",
  "chief information" = "chief information officer",
  "chief marketing" = "chief marketing officer",
  "chief revenue" = "chief revenue officer",
  "chief product" = "chief product officer",
  "chief people" = "chief people officer",
  "chief customer" = "chief customer officer",
  "chief legal" = "chief legal officer",
  "chief compliance" = "chief compliance officer",
  "chief risk" = "chief risk officer",
  "chief security" = "chief security officer",
  "chief data" = "chief data officer",
  "chief analytics" = "chief analytics officer",

  "manger" = "manager",
  "mngr" = "manager",
  "managr" = "manager",
  "dirctor" = "director",
  "directer" = "director",
  "v p" = "vice president",
  "svp" = "senior vice president",
  "evp" = "executive vice president",
  "avp" = "assistant vice president",
  "vpres" = "vice president",
  "vice pres" = "vice president",
  "vice-president" = "vice president",

  "asst" = "assistant",
  "assitant" = "assistant",
  "assisstant" = "assistant",
  "assoc" = "associate",
  "assc" = "associate",
  "sr" = "senior",
  "s r" = "senior",
  "snr" = "senior",
  "senr" = "senior",
  "jr" = "junior",
  "j r" = "junior",
  "jnr" = "junior",
  "lead" = "lead",
  "principal" = "principal",
  "prinicipal" = "principal",
  "pricipal" = "principal",
  "staff" = "staff",
  "intern" = "intern",
  "trainee" = "trainee",
  "apprentice" = "apprentice",

  # --- founders / ownership ---
  "co founder" = "cofounder",
  "co-founder" = "cofounder",
  "cofounder" = "cofounder",
  "founder" = "founder",
  "owner" = "owner",
  "proprietor" = "owner",
  "partner" = "partner",
  "managing partner" = "managing partner",

  # --- C-suite acronyms (expand) ---
  "ceo" = "chief executive officer",
  "coo" = "chief operating officer",
  "cfo" = "chief financial officer",
  "cto" = "chief technology officer",
  "cio" = "chief information officer",
  "cmo" = "chief marketing officer",
  "cro" = "chief revenue officer",
  "cpo" = "chief product officer",
  "cdo" = "chief data officer",              # sometimes "chief digital officer"—watch ambiguity
  "cso" = "chief security officer",          # sometimes "chief strategy officer"—watch ambiguity
  "chro" = "chief human resources officer",
  "clo" = "chief legal officer",
  "cco" = "chief compliance officer",        # sometimes "chief commercial officer"—watch ambiguity
  "ciso" = "chief information security officer",
  "cbo" = "chief business officer",
  "cxo" = "chief executive officer",

  # --- senior leadership / exec roles ---
  "pres" = "president",
  "president" = "president",
  "vice president" = "vice president",
  "senior vice president" = "senior vice president",
  "executive vice president" = "executive vice president",
  "managing director" = "managing director",
  "md" = "managing director",                # ambiguous in healthcare
  "gm" = "general manager",                  # ambiguous but common
  "general mgr" = "general manager",

  # --- management / leadership ---
  "dir" = "director",
  "director" = "director",
  "sr director" = "senior director",
  "senior director" = "senior director",
  "exec director" = "executive director",
  "executive director" = "executive director",

  "mgr" = "manager",
  "manager" = "manager",
  "sr mgr" = "senior manager",
  "senior manager" = "senior manager",
  "asst manager" = "assistant manager",
  "assistant manager" = "assistant manager",

  "supervisor" = "supervisor",
  "team lead" = "team lead",
  "tl" = "team lead",                        # can be noisy—watch ambiguity

  # --- functional common abbreviations ---
  "hr" = "human resources",
  "it" = "information technology",
  "pr" = "public relations",
  "qa" = "quality assurance",
  "qc" = "quality control",
  "ops" = "operations",
  "biz dev" = "business development",
  "bd" = "business development",             # ambiguous (can be “board” in some contexts)
  "sales rep" = "sales representative",
  "rep" = "representative",
  "sr rep" = "senior representative",

  # --- engineering / tech ---
  "swe" = "software engineer",
  "sdet" = "software development engineer in test",
  "devops" = "devops",
  "dev ops" = "devops",
  "secops" = "security operations",
  "data sci" = "data scientist",
  "ds" = "data scientist",                   # ambiguous
  "ml" = "machine learning",
  "ai" = "artificial intelligence",

  # --- product / project (high ambiguity) ---
  "pm" = "project manager",                  # could be product manager
  "pmo" = "project management office",
  "po" = "product owner",
  "scrum master" = "scrum master",

  # --- finance / accounting ---
  "acct" = "accountant",
  "accounting" = "accounting",
  "fp a" = "financial planning and analysis",
  "fpa" = "financial planning and analysis",
  "ap" = "accounts payable",
  "ar" = "accounts receivable",
  "cpa" = "certified public accountant",

  # --- legal / compliance / risk ---
  "gc" = "general counsel",
  "counsel" = "counsel",
  "attorney" = "attorney",
  "compliance" = "compliance",
  "risk" = "risk",
  "audit" = "audit",

  # --- customer / service / success ---
  "cs" = "customer success",                 # ambiguous (computer science)
  "csr" = "customer service representative",
  "support" = "support",
  "customer support" = "customer support",

  # --- misc common role words ---
  "admin" = "administrator",
  "administrator" = "administrator",
  "assistant" = "assistant",
  "coordinator" = "coordinator",
  "specialist" = "specialist",
  "analyst" = "analyst",
  "consultant" = "consultant",
  "engineer" = "engineer",
  "developer" = "developer"
)

```

```{r}
replace_word <- function(x, from, to) {
  str_replace_all(x, regex(paste0("\\b", from, "\\b"), ignore_case = TRUE), to)
}
```

```{r}
leads <- leads |>
  mutate(
    contact_lead_title = reduce(
      names(title_map),
      .init = contact_lead_title,
      .f = \(acc, k) replace_word(acc, k, title_map[[k]])
    ) |>
      str_replace_all("\\s+", " ") |>
      str_trim()
  )
```


```{r}

leads |>
  summarise(n = n(), n_unique = n_distinct(contact_lead_title),
            n_missing = sum(is.na(contact_lead_title) | contact_lead_title == ""))

```
**Contact Lead Title Grouping Output**

This further reduces the unique values down by another ~100 values. The problem at this step is that there are varying combinations of common words that can occur in different frequencies. 

#### Contact Lead Title Word Cloud

If we look at a word cloud of the most common 50 words, there is no surprise at what shows up the most frequently. 

```{r fig.width= 10, fig.height = 10}
#remove whitespace
par(mar = c(0,0,0,0), oma = c(0,0,0,0), xaxs = "i", yaxs = "i")

corp <- corpus(leads, text_field = "contact_lead_title")
toks <- tokens(corp)
dfm_mat <- dfm(toks)

textplot_wordcloud(dfm_mat, max_words = 50, max_size = 6, min_size = 0.5)
```
**Word Cloud Output**
Manager, quality, director, assurance, and senior are the most common words implicated by the word cloud.

#### Most Common Word Data Frame

To account for the various combination of words, a data frame is created of the most common occurring words. Only words that occur at least 5 times are retained. These words will be used to create a flag variable if that word occurred or not. 

```{r}

top_features <- topfeatures(dfm_mat,10000)

top_features_df <- data.frame(
  feature = names(top_features),
  count = as.numeric(top_features))

count(top_features_df)

non_blank <- leads |>
  summarise(n = n() - sum(is.na(contact_lead_title) | contact_lead_title == "")) |>
  pull(n)
  
top_features_df <- top_features_df |> filter(count >= 5)
top_features_df <- top_features_df |> mutate(percentage_occured_non_blank = count / non_blank)
head(top_features_df,10)
tail(top_features_df,10)

```

**Common Words Data Frame Output**

Above shows the top 10 occurring words, as well as 10 that only occur 5 times, and for both of these  In total 361 words clear this threshold. 
It also has the count of unique words in general that occur, of which their are 2,137.

We can see from below that ~34% of titles have "quality", and ~30% have manager. 

#### Common Words Bi-Grams

Additionally we can look at just bi-grams (sequences of only two words from the title field), if we look at this it does give us some more information in regards to word order. However, the number of unique word combinations then goes back up greatly, so this will not be further evaluated. 

```{r}
toks_bigram <-tokens_ngrams(toks,n = 2)
dfm_bigram <-dfm(toks_bigram)

top_features_bi <- topfeatures(dfm_bigram,10000)

top_features_df_bi <- data.frame(
  feature = names(top_features_bi),
  count = as.numeric(top_features_bi))

count(top_features_df_bi)

top_features_df_bi <- top_features_df_bi |> filter(count >= 5)
top_features_df_bi <- top_features_df_bi |> mutate(percentage_occured_non_blank = count / non_blank)
head(top_features_df_bi,10)

```


### Clean Dataset

In this section, we create a cleaned version of the leads dataset that we can use for EDA (and later modeling) without removing rows.

#### **Steps:**

-   Keep all original columns

-   Standardize “missing-like” text in categorical fields by converting blanks and placeholder values (e.g., "Unknown", "Not Enough Info Found", "MISSING/BLANK") into true NA.

-   Use a recipes pipeline to replace NA values in categorical predictor columns only with a consistent category level called "Low Info" so incomplete enrichment is explicit and rows are retained.

-   Create indicator flags (site_lowinfo, mfg_lowinfo, title_lowinfo, site_or_mfg_lowinfo) that capture whether key enrichment fields ended up as "Low Info".

-   We **do not modify** `next_stage_c` in the recipe because it represents the outcome; any missing outcomes remain missing and are handled separately when computing success rates.

```{r Recipe-Cleaning}

# Drop rows with missing target/outcome
leads_model <- leads %>%
  filter(!is.na(next_stage_c))

# Convert placeholder text + blanks to NA (for character/factor columns)
to_na_lowinfo <- function(x) {
  x <- str_trim(x)
  x <- na_if(x, "")
  x <- if_else(
    str_to_lower(x) %in% c("missing/blank", "unknown", "not enough info found"),
    NA_character_,
    x
  )
  x
}

rec_clean_only <- recipe(~ ., data = leads_model) %>%
  # Keep IDs as-is (do not clean/encode them as predictors)
  update_role(qal_id, contact_lead_id, new_role = "id") %>%
  
  # Keep outcome column as-is (do not clean it as a predictor)
  update_role(next_stage_c, new_role = "outcome") %>%
  
  # Clean categorical predictors ONLY (excludes id + outcome roles)
  step_mutate_at(all_nominal_predictors(), fn = to_na_lowinfo) %>%
  
  # Replace NA in categorical predictors with a consistent level
  step_unknown(all_nominal_predictors(), new_level = "Low Info") %>%
  
  # Create flags AFTER "Low Info" exists
  step_mutate(
    site_lowinfo        = acct_primary_site_function == "Low Info",
    mfg_lowinfo         = acct_manufacturing_model   == "Low Info",
    title_lowinfo       = contact_lead_title         == "Low Info",
    site_or_mfg_lowinfo = site_lowinfo | mfg_lowinfo
  )

# Apply recipe
prep_clean_only <- prep(rec_clean_only, training = leads_model, retain = TRUE)
leads_cleaned_only <- bake(prep_clean_only, new_data = NULL)

# Quick checks
dim(leads)
dim(leads_cleaned_only)
colSums(is.na(leads_cleaned_only))
table(leads_cleaned_only$site_or_mfg_lowinfo, useNA = "ifany")

```

-   Once the recipe has done the data cleaning the last step is merging the one hot encoded data back to the main cleaned data frame.

```{r}
#change from factor before creating corpus/tokens
leads_cleaned_only <- leads_cleaned_only %>%
  mutate(contact_lead_title = as.character(contact_lead_title))

#create corpus and tokens 
corp <- corpus(
  leads_cleaned_only,
  text_field = "contact_lead_title")

toks <- tokens(corp)

toks_onehot <- tokens_select(
  toks,
  pattern = top_features_df$feature)

#create one hot encoded matrix
dfm_onehot <- dfm(toks_onehot)
dfm_onehot_bin <- dfm_weight(dfm_onehot, scheme = "boolean")
df_encoded <- convert(dfm_onehot_bin, to = "data.frame")

#join back together
leads_cleaned_only <-cbind(leads_cleaned_only, df_encoded[,-1])

#check duplicated columns for target variable binary conversion
colnames(leads_cleaned_only)[duplicated(colnames(leads_cleaned_only))]

dup_cols <- colnames(leads_cleaned_only)[colnames(leads_cleaned_only) %in% colnames(leads_cleaned_only)[duplicated(colnames(leads_cleaned_only))]]
dup_cols

leads_cleaned_only[, dup_cols]

#drop solution.1
leads_cleaned_final <- leads_cleaned_only[, colnames(leads_cleaned_only) != "solution.1"]
leads_cleaned_final

#check for duplicates again
colnames(leads_cleaned_final)[duplicated(colnames(leads_cleaned_final))]

#now convert target to binary
leads_cleaned_final <- leads_cleaned_final %>%
  mutate(
    next_stage_target = factor(
      if_else(next_stage_c %in% c("SQL", "SQO", "Won"), 1, 0)
    )
  )

#view dataframe
leads_cleaned_final
```


#### Interpretation (Clean Dataset checks)

-   **Shape:** The full dataset (`leads`) contains **16,815 rows** and **14 columns**.\
    For modeling, we drop rows with missing outcome (`next_stage_c`), resulting in **16,332 rows**.\
    After applying the recipe, the cleaned modeling dataset keeps **all 16,332 rows** and increases to **3379 columns** because we added 4 flags for low information and 361 for word occurrences  :\
    `site_lowinfo`, `mfg_lowinfo`, `title_lowinfo`, `site_or_mfg_lowinfo`.\
    When converting the target variable `next_stage_c` to binary (1,0), the error of duplicate column names was returned. We checked which columns we duplicated, 'solution' was the duplicated column, and then removed it. Then we continued with turning the target variable into binary and it worked successfully.
    
-   **Missing values after recipe (`colSums(is.na())`):**

    -   `acct_primary_site_function`, `acct_manufacturing_model`, `contact_lead_title` now have **0 NA** because NAs + placeholder values were standardized and replaced with the factor level **"Low Info"**.
    -   `next_stage_c` has **0 NA** in the cleaned modeling dataset because rows with missing outcomes were removed **before** the recipe (`filter(!is.na(next_stage_c))`).
    -   `contact_lead_id` still has **2 NA** (ID column kept as-is and not imputed).

-   **Low-info flag (`table(site_or_mfg_lowinfo)`):**

    -   `FALSE = 7,859`: both site + manufacturing enrichment are present (not **"Low Info"**)
    -   `TRUE  = 8,473`: **at least one** of site or manufacturing is **"Low Info"**

**Key takeaway:** After restricting to leads with known outcomes, low-enrichment (**"Low Info"**) values remain very common and should be treated as signal rather than noise. We standardize missing/placeholder values into a consistent **"Low Info"** category for categorical predictors and create indicator flags (e.g., `site_or_mfg_lowinfo`, `title_lowinfo`) so downstream models can learn the relationship between enrichment quality and lead progression.